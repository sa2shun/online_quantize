{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7990b71d-ba4b-4f52-91c1-078cd25b0063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be saved to: /raid/sasaki/meta-llama_Llama-3.1-70B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53ecf541b384369be518aa557c3e0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd94b166d2324ab086880e5c4b4cba53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n",
      "All files are saved in: /raid/sasaki/meta-llama_Llama-3.1-70B-Instruct\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login, HfApi\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers.models.llama import LlamaConfig\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Hugging Faceにログイン\n",
    "# 環境変数 HUGGINGFACE_TOKEN が設定されていれば自動的に利用\n",
    "token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "# モデルディレクトリと保存先パス\n",
    "base_model_name = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "\n",
    "# ユーザー名を取得して/raidに保存パスを設定\n",
    "user_dir = os.environ.get(\"USER\")\n",
    "save_directory = f\"/raid/{user_dir}/{base_model_name.replace('/', '_')}\"\n",
    "\n",
    "# 保存ディレクトリを作成\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "print(f\"Model will be saved to: {save_directory}\")\n",
    "\n",
    "# int4量子化の設定\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.torch.bfloat16  # 計算をfloat16で実行\n",
    ")\n",
    "\n",
    "# モデル構成の設定（rope_scaling対策）\n",
    "config = LlamaConfig.from_pretrained(base_model_name, cache_dir=save_directory)\n",
    "if hasattr(config, \"rope_scaling\"):\n",
    "    config.rope_scaling[\"original_max_position_embeddings\"] = 8191  # 調整して問題を解決\n",
    "\n",
    "# トークナイザのロード\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, cache_dir=save_directory, token=token)\n",
    "\n",
    "# `pad_token_id` を設定（未設定の場合）\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# 通常モデルのロード\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    config=config,        \n",
    "    device_map=\"auto\",           \n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=save_directory,    \n",
    "    token=token\n",
    ")\n",
    "\n",
    "# 量子化モデルのロード\n",
    "model_quantized = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    config=config,   \n",
    "    device_map=\"auto\",           \n",
    "    quantization_config=bnb_config,  \n",
    "    cache_dir=save_directory,   \n",
    "    token=token         \n",
    ")\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")\n",
    "print(f\"All files are saved in: {save_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e434e5-e0c2-4ebb-a880-52abde9b4cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model - Parameter: model.embed_tokens.weight, Device: cuda:0\n",
      "Quantized Model - Parameter: model.embed_tokens.weight, Device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# モデルがどのデバイスに載っているかを出力する関数\n",
    "def print_model_device_info(model, model_name):\n",
    "    for param_name, param in model.named_parameters():\n",
    "        print(f\"{model_name} - Parameter: {param_name}, Device: {param.device}\")\n",
    "        break  # 最初のパラメータで終了\n",
    "\n",
    "print_model_device_info(model_base, \"Base Model\")\n",
    "print_model_device_info(model_quantized, \"Quantized Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b7edc2-2de7-4318-89f1-5f449d9f8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_task_difficulty(input_text: str) -> float:\n",
    "    \"\"\"\n",
    "    タスクの難易度を測定する関数。ここでは文字数やトークン数、構造の複雑さなどを基準に仮定。\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(input_text)\n",
    "    # 難易度はトークン数で計測（仮）\n",
    "    difficulty = len(tokens)\n",
    "    return difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bab2d4-9f91-48a1-9670-1848bdbba71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(difficulty: float, threshold: float = 50) -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    難易度に応じて使用するモデルを選択。\n",
    "    thresholdを超える場合、32-bitモデルを使用。\n",
    "    \"\"\"\n",
    "    if difficulty > threshold:\n",
    "        return model_base, tokenizer\n",
    "    else:\n",
    "        return model_quantized, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444736b8-f0ed-435a-ae55-2184e967411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(model, tokenizer, input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    指定したモデルとトークナイザを用いて出力を生成。\n",
    "    \"\"\"\n",
    "    # トークナイズ\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 不要なフィールドを削除\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        del inputs[\"token_type_ids\"]\n",
    "\n",
    "    # 生成\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        pad_token_id=tokenizer.pad_token_id  # トークナイザの設定済みpad_token_idを利用\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bbe651-5fdc-4715-a167-a17742bc82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# メイン処理\n",
    "def process_input(input_text: str, difficulty_threshold: float = 50) -> str:\n",
    "    \"\"\"\n",
    "    タスク全体を実行するメイン関数。\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. タスクの難易度を測定\n",
    "    difficulty = calculate_task_difficulty(input_text)\n",
    "\n",
    "    # 2. 適切なモデルを選択\n",
    "    model, tokenizer = select_model(difficulty, difficulty_threshold)\n",
    "\n",
    "    # 3. 出力を生成\n",
    "    output = generate_output(model, tokenizer, input_text)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Using model: {'Base model' if model == model_base else 'Quantized'}\")\n",
    "    print(f\"Task Difficulty: {difficulty}\")\n",
    "    print(f\"Processing Time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b08903-468a-4564-af54-52710576470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Using model: Quantized\n",
      "Task Difficulty: 4\n",
      "Processing Time: 62.54 seconds\n",
      "Generated Output: Please explain Linear Algebra\n",
      "Linear algebra is a branch of mathematics that deals with the study of linear equations, vector spaces, linear transformations, and linear operators. It is a fundamental subject that has numerous applications in various fields, including physics, engineering, computer science, and data analysis. Here's a comprehensive overview of linear algebra:\n",
      "**Key Concepts:**\n",
      "\n",
      "1. **Vector Spaces:** A vector space is a set of vectors that can be added and scaled (multiplied by a scalar). Vector spaces can be finite-dimensional (e.g., 2D, 3D) or infinite-dimensional.\n",
      "2. **Linear Independence:** A set of vectors is said to be linearly independent if none of the vectors can be expressed as a linear combination of the others.\n",
      "3. **Span:** The span of a set of vectors is the set of all linear combinations of those vectors.\n",
      "4. **Basis:** A basis is a set of linearly independent vectors that span a vector space.\n",
      "5. **Linear Transformations:** A linear transformation is a function between vector spaces that preserves the operations of vector addition and scalar multiplication.\n",
      "6. **Matrices:** Matrices are rectangular arrays of numbers used to represent linear transformations and perform calculations.\n",
      "\n",
      "**Important Theorems:**\n",
      "\n",
      "1. **The Fundamental Theorem of Linear Algebra:** Every finite-dimensional vector space has a basis, and any two bases have the same number of elements (dimension).\n",
      "2. **The Rank-Nullity Theorem:** The rank of a linear transformation (the dimension of its image) plus the nullity (the dimension of its kernel) equals the dimension of the domain.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "1. **Computer Graphics:** Linear algebra is used to perform transformations, projections, and animations in computer graphics.\n",
      "2. **Machine Learning:** Linear algebra is used in machine learning to perform tasks such as data preprocessing, feature extraction, and model training.\n",
      "3. **Physics and Engineering:** Linear algebra is used to describe the motion of objects, forces, and energies in physics and engineering.\n",
      "4. **Data Analysis:** Linear algebra is used in data analysis to perform tasks such as data visualization, dimensionality reduction, and regression analysis.\n",
      "\n",
      "**Common Operations:**\n",
      "\n",
      "1. **Vector Addition:** Adding two or more vectors element-wise.\n",
      "2. **Scalar Multiplication:** Multiplying a vector by a scalar (a number).\n",
      "3. **Matrix Multiplication:** Multiplying two matrices to perform a linear transformation.\n",
      "4. **Determinant Calculation:** Calculating the determinant of a matrix to determine its invertibility and other properties.\n",
      "\n",
      "**Key Techniques:**\n",
      "\n",
      "1. **Gaussian Elimination:** A method for solving systems of linear equations by transforming the augmented matrix into row-echelon form.\n",
      "2. **Eigenvalue Decomposition:** A method for diagonalizing a matrix by finding its eigenvalues and eigenvectors.\n",
      "3. **Singular Value Decomposition (SVD):** A method for decomposing a matrix into three matrices, which is useful for image compression and other applications.\n",
      "\n",
      "**Real-World Examples:**\n",
      "\n",
      "1. **Image Processing:** Linear algebra is used in image processing to perform tasks such as image filtering, edge detection, and image compression.\n",
      "2. **Robotics:** Linear algebra is used in robotics to perform tasks such as motion planning, control, and sensor fusion.\n",
      "3. **Signal Processing:** Linear algebra is used in signal processing to perform tasks such as filtering, modulation, and demodulation.\n",
      "\n",
      "In conclusion, linear algebra is a fundamental subject that provides a powerful framework for solving systems of linear equations, transforming vectors, and analyzing data. Its applications are diverse and widespread, and it is an essential tool for anyone working in fields that involve mathematical modeling and data analysis.\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "input_text = \"Please explain Linear Algebra\"\n",
    "result = process_input(input_text)\n",
    "print(\"Generated Output:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c66f50-f767-4c32-829f-f2d0fecf26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_inputs = [\n",
    "    \"Hello, how is the weather today?\",\n",
    "    \"Can you recommend some popular spots in Tokyo?\",\n",
    "    \"What are your thoughts on the future of technology?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a957ebc-b114-40bc-95ad-d0e2616868f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Base Model:\n",
      "==================================================\n",
      "Using model: Base model\n",
      "Task Difficulty: 8\n",
      "Processing Time: 12.04 seconds\n",
      "==================================================\n",
      "Using model: Base model\n",
      "Task Difficulty: 9\n",
      "Processing Time: 75.18 seconds\n",
      "==================================================\n",
      "Using model: Base model\n",
      "Task Difficulty: 10\n",
      "Processing Time: 45.70 seconds\n",
      "Using Quantized Model:\n",
      "==================================================\n",
      "Using model: Quantized\n",
      "Task Difficulty: 8\n",
      "Processing Time: 4.32 seconds\n",
      "==================================================\n",
      "Using model: Quantized\n",
      "Task Difficulty: 9\n",
      "Processing Time: 38.58 seconds\n",
      "==================================================\n",
      "Using model: Quantized\n",
      "Task Difficulty: 10\n",
      "Processing Time: 50.08 seconds\n"
     ]
    }
   ],
   "source": [
    "# 短い入力を処理\n",
    "print(\"Using Base Model:\")\n",
    "for input_text in short_inputs:\n",
    "    result = process_input(input_text, difficulty_threshold=0)\n",
    "\n",
    "# 長い入力を処理\n",
    "print(\"Using Quantized Model:\")\n",
    "for input_text in short_inputs:\n",
    "    result = process_input(input_text, difficulty_threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d5d480e-3145-421a-9a6f-71e35da81d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 25 04:27:25 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A30                     Off |   00000000:B5:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             31W /  165W |   18001MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2131200      C   .../sfc-llm-w8I0Ke9S-py3.10/bin/python      17992MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c238a58-c2be-446b-b5f1-395c7ea214ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison complete. Results saved to: glue_comparison_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ファイル名を指定\n",
    "file1 = \"glue_comparison_results_meta-llama_Llama-3.1-70B-Instruct_mrpc_20241129_105418.csv\"\n",
    "file2 = \"10ex_glue_comparison_results.csv\"\n",
    "\n",
    "# CSVファイルの読み込み\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# 各種統計情報の計算関数\n",
    "def calculate_summary(df):\n",
    "    return {\n",
    "        \"base_model_accuracy\": df[\"base_model_correct\"].mean() * 100,  # Baseモデルの正答率 (%)\n",
    "        \"quantized_model_accuracy\": df[\"quantized_model_correct\"].mean() * 100,  # 量子化モデルの正答率 (%)\n",
    "        \"base_model_avg_time\": df[\"base_model_time\"].mean(),  # Baseモデルの平均実行時間 (秒)\n",
    "        \"quantized_model_avg_time\": df[\"quantized_model_time\"].mean(),  # 量子化モデルの平均実行時間 (秒)\n",
    "        \"base_model_time_std\": df[\"base_model_time\"].std(),  # Baseモデル実行時間の標準偏差 (秒)\n",
    "        \"quantized_model_time_std\": df[\"quantized_model_time\"].std()  # 量子化モデル実行時間の標準偏差 (秒)\n",
    "    }\n",
    "\n",
    "# それぞれのデータの統計情報を計算\n",
    "summary1 = calculate_summary(df1)\n",
    "summary2 = calculate_summary(df2)\n",
    "\n",
    "# 差異を計算\n",
    "comparison = {\n",
    "    key: summary1[key] - summary2[key]\n",
    "    for key in summary1\n",
    "}\n",
    "\n",
    "# 結果をデータフレームに変換して表示\n",
    "summary_df1 = pd.DataFrame([summary1], index=[\"File1\"])\n",
    "summary_df2 = pd.DataFrame([summary2], index=[\"File2\"])\n",
    "comparison_df = pd.DataFrame([comparison], index=[\"Difference\"])\n",
    "\n",
    "# 結果を保存または表示\n",
    "output_filename = \"glue_comparison_summary.csv\"\n",
    "result_df = pd.concat([summary_df1, summary_df2, comparison_df])\n",
    "result_df.to_csv(output_filename)\n",
    "\n",
    "print(\"Comparison complete. Results saved to:\", output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1ec78-bdbe-4e01-b750-136634a08801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
